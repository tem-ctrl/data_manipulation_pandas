{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c1ee5d2",
   "metadata": {},
   "source": [
    "# Pandas Techniques for Data Manipulation in Python\n",
    "G. Temgoua \n",
    "[Github](https://github.com/tem-ctrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91644ee",
   "metadata": {},
   "source": [
    "![image](data_science.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aa4332",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Without **data**, there won't be neither **data science** nor **data scientists**, that is why efficient data manipulation skills come in very handy. However, real-world data is always dirty, besides some tasks require us to use only part of data or to combine two or more datasets into one and so on. All these tasks have been made quite easy in Python by the **Pandas library**. In this post, we will present five powerful techniques offered by Pandas for manipulating data in order to draw useful insights from it. These techniques, in order of appearence in the text are: **Importing data, Apply functions, Imputing missing values, working with categorical data** and **Manipulating text data**. The Ukrainian coffee market dataset downloaded from [Kaggle](https://www.kaggle.com/dimitryzub/10-coffee-places-from-ukrainian-cities) will be used for illustration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bae7ad",
   "metadata": {},
   "source": [
    "## 1. Importing data with Pandas\n",
    "\n",
    "Regarding the size, type, user's preferences, the data is stored in many different file formats including but not limited to:\n",
    "- CSV (Comma Separated Values);\n",
    "- HDF5 (Hierarchical Data Format, version 5);\n",
    "- SQL databases;\n",
    "- JSON;\n",
    "- Excel spreadsheets;\n",
    "\n",
    "With pandas reading functions, the data stored in each of these file formats is loaded into a pandas DataFrame. For the file formats listed above, the corresponding reading functions are listed below, in the same order posterior to loading pandas under its common alias **pd**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7f42fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data_path = 'coffee_shops.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "# df = pd.read_csv('path/to/data.csv') # Load a CSV file\n",
    "# df = pd.read_hdf('path/to/data.hdf5') # Load a hdf5 file\n",
    "# df = pd.read_sql('SQL query')\n",
    "# df = pd.read_json('path/to/data.json')\n",
    "# df = pd.read_excel('path/to/data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da85495",
   "metadata": {},
   "source": [
    "**Note:** For online data scraping, we just need to replace **path/to/data.ext** by its corresponding URL. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e349b5",
   "metadata": {},
   "source": [
    "Once the data is loaded, good practices expect us to learn to know our data, number of columns, rows, their data types, the summary statistics, check for missing values and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "301b7991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Place name</th>\n",
       "      <th>Place type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Price</th>\n",
       "      <th>Delivery option</th>\n",
       "      <th>Dine in option</th>\n",
       "      <th>Takeout option</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mariupol</td>\n",
       "      <td>Dim Kavu</td>\n",
       "      <td>Coffee store</td>\n",
       "      <td>4.6</td>\n",
       "      <td>206.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mariupol</td>\n",
       "      <td>Коферум</td>\n",
       "      <td>Cafe</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>$$</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mariupol</td>\n",
       "      <td>Кофейня Світ Чаю</td>\n",
       "      <td>Coffee shop</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mariupol</td>\n",
       "      <td>Кофейня Starcoff</td>\n",
       "      <td>Coffee shop</td>\n",
       "      <td>4.4</td>\n",
       "      <td>331.0</td>\n",
       "      <td>$$</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mariupol</td>\n",
       "      <td>Кофейня \"Friend Zone\"</td>\n",
       "      <td>Coffee shop</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Region             Place name    Place type  Rating  Reviews Price  \\\n",
       "0  Mariupol               Dim Kavu  Coffee store     4.6    206.0   NaN   \n",
       "1  Mariupol                Коферум          Cafe     5.0     24.0    $$   \n",
       "2  Mariupol       Кофейня Світ Чаю   Coffee shop     5.0     11.0   NaN   \n",
       "3  Mariupol       Кофейня Starcoff   Coffee shop     4.4    331.0    $$   \n",
       "4  Mariupol  Кофейня \"Friend Zone\"   Coffee shop     5.0     12.0   NaN   \n",
       "\n",
       "  Delivery option Dine in option Takeout option  \n",
       "0             NaN            NaN            NaN  \n",
       "1           False            NaN           True  \n",
       "2             NaN            NaN           True  \n",
       "3           False           True           True  \n",
       "4             NaN           True           True  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd009e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Region           200 non-null    object \n",
      " 1   Place name       200 non-null    object \n",
      " 2   Place type       200 non-null    object \n",
      " 3   Rating           198 non-null    float64\n",
      " 4   Reviews          198 non-null    float64\n",
      " 5   Price            122 non-null    object \n",
      " 6   Delivery option  129 non-null    object \n",
      " 7   Dine in option   140 non-null    object \n",
      " 8   Takeout option   144 non-null    object \n",
      "dtypes: float64(2), object(7)\n",
      "memory usage: 14.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0629ed",
   "metadata": {},
   "source": [
    "## 2. Apply functions\n",
    "\n",
    "Pandas offers the possibility to apply one or many functions at once to certain parts of the dataframe. These functions can either be python built-ins or user defined. There are several ways to apply functions to dataframes but in this tutorial we will talk about two functions.\n",
    "- `apply()` which allows to manipulate the data as a whole;\n",
    "- `applymap()` which is used to aplly functions to the data elementwise.\n",
    "\n",
    "### 2.1 Apply a single function\n",
    "These functions include `min()`, `mean()`, `max()`, `std` and many others that permit to draw useful insights from the data they are applied on. <br>\n",
    "For illustration, let's evaluate the mean of the numerical columns(`Rating` and `Reviews`) of our dataset on one hand, on the other hand we will create a new column `len_place_type` to store the number of characters of each `Place type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea22d90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reviews    622.494949\n",
       "Rating       4.663636\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Reviews', 'Rating']].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a00af658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12\n",
       "1     4\n",
       "2    11\n",
       "3    11\n",
       "4    11\n",
       "Name: len_place_type, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda x: len(x)\n",
    "df['len_place_type'] = df[['Place type']].applymap(f)\n",
    "df.len_place_type.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db02b4d",
   "metadata": {},
   "source": [
    "### 2.2 Apply multiple functions\n",
    "To agregate data with more than one function using the `apply()` method, we simply pass the functions as a list. Let's compute the `min` and `max` values of both `Reviews` and `rating` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c587aee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amin</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amax</th>\n",
       "      <td>17937.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Reviews  Rating\n",
       "amin      3.0     3.9\n",
       "amax  17937.0     5.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Reviews', 'Rating']].apply([np.min, np.max])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c62a3cb",
   "metadata": {},
   "source": [
    "As can be seen, pandas gives the result as a new dataframe. <br>\n",
    "*Important note: when applying functions to data, missing values are ignored*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3107df76",
   "metadata": {},
   "source": [
    "## 3. Imputing missing values\n",
    "Unless specially specified, missing values are represented by **NaN** or **NA** (More recent).\n",
    "The `info()` method used to retrieve general information of the dataset shows that there are some missing values but the specialized methods for detecting missing values are `isna()` and `isnull`, both somewhat equivalent. We use `isna()` here, combinbed with the method `any()`, it yields a pandas series of type `Boolean` with the value `True` for each column with missing values and `False` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07b3815c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region             False\n",
       "Place name         False\n",
       "Place type         False\n",
       "Rating              True\n",
       "Reviews             True\n",
       "Price               True\n",
       "Delivery option     True\n",
       "Dine in option      True\n",
       "Takeout option      True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed26b6c",
   "metadata": {},
   "source": [
    "Combined with `sum()`, it gives a series with all the dataframe column names and their corresponding number of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3d344bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region               0\n",
       "Place name           0\n",
       "Place type           0\n",
       "Rating               2\n",
       "Reviews              2\n",
       "Price               78\n",
       "Delivery option     71\n",
       "Dine in option      60\n",
       "Takeout option      56\n",
       "mean_diff_rating     2\n",
       "len_place_type       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957319a9",
   "metadata": {},
   "source": [
    "There are numerous ways of dealing with missing data, the most drastical one being dropping every row with missing values. this is achieved by the pandas function `dropna()`. For datasets with many missing values, this approached should definitely be avoided, as can be confirmed by the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76c5f572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drop = df.dropna()\n",
    "len(df_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24d83e4",
   "metadata": {},
   "source": [
    "Another common way of treating missing values is to replace them by a certain value, the aim being to reproduce the data original data distribution as fidelly as possible. To do so, we use the pandas method `fillna()`, the first parameter being the value with which we want to replace missing values. The most common technique is to replace missing values in a dataset column with the most frequent value of the column in question, however the imputation strategy completely depends on the data scientist, their data distribution and their expectations. <br>\n",
    "In our dataframe, the missing values in `Dine in option` and `Takeout option` columns correspond to the boolean value `False`, so let's fix that. The parameter `inplace` set to `True` allows the modification to be done inplce, no need to create a copy of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dfd235ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values by False\n",
    "df['Dine in option'].fillna(False, axis=0, inplace=True)\n",
    "df['Takeout option'].fillna(False, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5be54a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dine in option    False\n",
       "Takeout option    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Dine in option', 'Takeout option']].isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce6093b",
   "metadata": {},
   "source": [
    "## 4. Working with categorical data\n",
    "\n",
    "As indicated by its name, categorical data type is the pandas equivalent of categorical data in statistics. This data type is used to describe data that usually takes a limited, fixed amount of possible values. e.g. the days of a the week, the months of the year... \n",
    "\n",
    "The categorical data type is best suited in the following situations:\n",
    "- A string variable taking few values, eg: the `Place type` and `Region` column of our dataset.\n",
    "- The logical order (`1, 2, 3`) order of a variable is different from the lexical order (`'one', 'three', 'two'`). \n",
    "- The other python libraries (**Matplotlib, seaborn...**) must interpret the variable as categorical, for plotting for example.\n",
    "\n",
    "### 4.1. Set column data type to categorical\n",
    "To change the data type of a variable in pandas, we use the method `astype()` which takes the new data type as parameter.\n",
    "Let's convert the data type of `Region` and `Place type` columns of our dataframe from `object` to `category`, which best describe the data in these columns. We will then have $10$ categories for `Region` and $14$ for `Place type` corresponding to the number of distinct values of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "69ba46a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region        category\n",
       "Place type    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Region', 'Place type']] = df[['Region', 'Place type']].astype('category')\n",
    "df[['Region', 'Place type']].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d916051",
   "metadata": {},
   "source": [
    "### 4.2. Label encoding\n",
    "Once the column data defined as categorical, Pandas offers the possibility throught the function `get_dummies()`, to encode the different values of that column as binary data, allowing it to be used in model training, evaluation and prediction. This function exploites the method known as **one-hot encoding**, that is every value of the column variable is reprensented by a binary word with length, the number of distinct values and all the bits but the one corresponding to the true value of the row, are set to `0`. \n",
    "\n",
    "Let's encode the values of the `Region` column as binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "730691c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kharkiv</th>\n",
       "      <th>Kherson</th>\n",
       "      <th>Khrivoy Rog</th>\n",
       "      <th>Kiev</th>\n",
       "      <th>Lviv</th>\n",
       "      <th>Mariupol</th>\n",
       "      <th>Odessa</th>\n",
       "      <th>Poltava</th>\n",
       "      <th>Zaporozhye</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Kharkiv  Kherson  Khrivoy Rog  Kiev  Lviv  Mariupol  Odessa  Poltava  \\\n",
       "0         0        0            0     0     0         1       0        0   \n",
       "25        0        0            0     0     0         0       0        1   \n",
       "45        0        1            0     0     0         0       0        0   \n",
       "65        0        0            0     0     0         0       0        0   \n",
       "85        0        0            0     0     0         0       1        0   \n",
       "\n",
       "    Zaporozhye  \n",
       "0            0  \n",
       "25           0  \n",
       "45           0  \n",
       "65           1  \n",
       "85           0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df['Region'], drop_first=True).iloc[[0, 25, 45, 65, 85]] #, prefix=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb3df96",
   "metadata": {},
   "source": [
    "## 5. Manipulating text data\n",
    "Pandas offers many method for an efficient text data management. Most importantly these methods automatically ignore missing values, avoiding annoying errors. The access to these useful method is made possible to dataframes throught the attribute `str`.\n",
    "\n",
    "### 5.1. some string methods\n",
    "Below are some common methods to used to deal with text.\n",
    "- `df.str.upper()` to convert text data to uppercase.\n",
    "- `df.str.lower()` to convert to lowercase.\n",
    "- `df.str.lstrip(), df.str.rstrip(), df.str.strip()` to trim white space at the begining, the end and both respectively.\n",
    "- `df.str.len()` to eveluate the length of text data.\n",
    "- `df.str.match('text')` to check whether or not the text data matches the text passed as parameter.\n",
    "\n",
    "Following are few example of usage of these methods on the `Place name` column of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "688df80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dim kavu'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'DIM KAVU'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places = df['Place name'].astype('string')\n",
    "places_low = places.str.lower()\n",
    "places_up = places.str.upper()\n",
    "places_len = places.str.len()\n",
    "# print the first value of each variant of dataframe\n",
    "display(places_low.iloc[0])\n",
    "display(places_up.iloc[0])\n",
    "places_len.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1474f8f",
   "metadata": {},
   "source": [
    "### 5.2. Split and replace text\n",
    "Using `str.split(delimiter)` on text data yields a list of different pices oc the text that can be accessed using `get()` method or `[]` notation. For example, if we split the first value of `places` series with the delimiter being the whitespace, we get a list of two words: `Dim` and `Kavu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06d41514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dim', 'Kavu']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places.iloc[0].split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf7182",
   "metadata": {},
   "source": [
    "The method `replace()` takes two mandatory parameters, the original text/character and the replavement text respectively. for illustration let's replace the white spaces by underscores in the `places` series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b38c70f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dim_Kavu'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places_und = places.str.replace(' ', '_')\n",
    "places_und[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb65e73",
   "metadata": {},
   "source": [
    "Pandas offers many other methods such as `cat` for manipulating text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1adcee3",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "In this post we covered few pandas techniques for data manipulation in python. However, this is just a glance compared to the number of methods offered by pandas for drawing useful insights from data. For a complete guide, refer to the [Pandas reference webpage](https://pandas.pydata.org/docs/user_guide/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b039461",
   "metadata": {},
   "source": [
    "https://www.datainsightonline.com/post/must-know-pandas-techniques-for-data-manipulation-in-python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
